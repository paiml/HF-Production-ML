# Lesson 1.1: Course Introduction & HuggingFace Publishing

## The Sovereign AI Stack

Build production ML systems with pure Rust—no Python runtime required.

| Crate | Purpose |
|-------|---------|
| **trueno** | SIMD & GPU compute primitives |
| **aprender** | ML algorithms, `.apr` format |
| **realizar** | Inference server, APIs |
| **batuta** | Orchestration, registry |

## HuggingFace Model Repositories

Every HF model repo contains four artifact types:

```
model-name/
├── model.safetensors    # Weights
├── tokenizer.json       # Tokenizer
├── config.json          # Architecture config
└── README.md            # Model card (metadata)
```

## Key Commands

```bash
# Pull a model from HuggingFace
apr pull hf.co/org/model-name

# List downloaded models
apr list

# Model info
apr info model-name
```

## Publishing Flow

1. Train or fine-tune model locally
2. Save weights + config + tokenizer
3. Write model card (README.md)
4. Push to HuggingFace Hub

## Key Takeaways

- One stack, no Python dependencies
- HuggingFace Hub = source of truth for models
- `apr pull` downloads to local sovereign stack
- Four artifacts per model: weights, tokenizer, config, metadata
