# Lesson 1.2: Model Types & APR Format

## Three Model Formats

| Format | Source | Best For |
|--------|--------|----------|
| **GGUF** | llama.cpp | CPU inference, quantization |
| **SafeTensors** | HuggingFace | Safe loading, HF ecosystem |
| **APR** | Sovereign Stack | WASM, edge, CUDA |

## GGUF Format

- Optimized for CPU inference
- Built-in quantization (Q4, Q8, etc.)
- Single file contains weights + metadata
- Consumer hardware friendly

## SafeTensors Format

- HuggingFace standard
- Memory-safe (no pickle)
- Zero-copy loading possible
- Multiple shards for large models

## APR Format

```
┌─────────────────────────────┐
│ Header (64 bytes)           │  ← One CPU cache line
├─────────────────────────────┤
│ JSON Metadata               │  ← Human readable
├─────────────────────────────┤
│ Tensor Data                 │  ← Aligned, mmap-ready
└─────────────────────────────┘
```

**APR advantages:**
- WASM-first design
- Scales to CUDA
- Sub-millisecond browser inference
- 64-byte header fits one cache line

## Format Selection Guide

| Deployment Target | Recommended Format |
|-------------------|-------------------|
| Browser (WASM) | APR |
| CPU server | GGUF or APR |
| GPU server | SafeTensors or APR |
| Edge/IoT | APR |
| HF ecosystem | SafeTensors |

## Key Takeaways

- GGUF = CPU + quantization
- SafeTensors = safe + HF standard
- APR = WASM + edge + universal
- Choose format based on deployment target
