{"text":" Many of the traditional concepts around DevOps still play a role in MLops. For example, CI/CD. You still want to have automated quality in fact in many ways it's even more important because there's increased complexity. The layers of your model, for example, or the configuration or the tokens or the embeddings, there's more complexity and so automated continuous improvements are even more important in terms of the word that's what MLOPS is all about. Let's take a look here at the pipeline stages. We have first source, this would be the get push or the PR merge that triggers the pipeline. We also have the ability to do cargo build, make compile. We have tests, so cargo tests, make land, the validation. You want to run benchmarking accuracy tests. All of the performance and correctness. So there are additional requirements because of the fact that there is complexity hidden inside of the model. For example, the layers, the accuracy of certain components, the embeddings that you're using, the tokenization that you're using, the correctness, the performance, there's so many different aspects that have to be validated. Finally, in terms of deployment, we have make deploy. It could be that a deployment is you publish a model, you use EPR published and you push your model to hugging of quality gaze, this is another thing to think about is how do you get the quality so that you cannot push a change that will destroy production. Compilation could be one. So you want zero warnings. You want also the build to succeed. You have test coverage, a component that I've seen that works pretty well is to have 95% minimum, but not just vague 95% but validated by mutation and also testing and also looking at the size of the files. You don't want files that are over 500 lines. All of these kinds of things fit into the test coverage beyond just the basic I want some tests. You need to have metrics that you look at and to make sure that anything that's missing tests is not a hidden technical debt bomb that will later explode in production. In terms of performance, we want to think of things like latency. So tracing many tokens per second? Accuracy you could have a golden dataset comparison or a ground truth. You don't want any of your questions against that and then also security. And then in terms of the feedback loops, this is another thing to think about is that if all of the gates are passing, this is a green light, you can promote to production. But if you have any failures, you can't just skip it. You need to block it, notify, fix it, no exceptions. And the pipeline will then predict. from having a bad deployment.","segments":[]}