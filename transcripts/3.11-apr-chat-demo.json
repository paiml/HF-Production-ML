{"text":" Here we have the APR chat prompt. In this case, we're going to use the .GGUF format. We could also download ASAPtenters format. We could download as well, APR format, or we could convert GGUF or savetenters to any format we want. In this case, though, let's start with something simple, and let's run GGUF. Now, to start with, we have information about the model. In this case, this is the path to the model we're using GPU inference for. We also have the template, the chat, ML template. You can customize this yourself and we have the temperature, the top p, the max tokens. And then in addition, we have some diagnostic information as well. So what is the format? When do we load the tokenizer? What are we actually detecting? Right. So these kinds of diagnostic tooling are built directly go through and we run something, we say, you know, what is the capital of France? There we go. You can see that we're able to talk to in my case the Nvidia RTX 4090 and we get a response to the capital of France as Paris. Now another component of this entire ecosystem is to run it with tracing. So if we enable trace, this is an important component of the software engineering best practices that have built this because when you're looking through a model that you were converting or changing or maybe distilling or fine tuning, the layers could have different information inside or you've made a performance regression. And so in this case, this detailed tracing will show up in the chat. So in this case, we'll say what is the capital of France? And now we're going to get detailed trace level performance. about this is we are able to trace not just the traditional performance of how the chat system works, but we also trace the model itself. What are the layers? What are the timings around the layers? What are we doing at the token level? And in fact, can we also look at the payloads that go into each layer and inspect them? And this is the power of using things where you have total control in one language in this case, Rust is that you have the ability to faster because of this level of observability.","segments":[]}