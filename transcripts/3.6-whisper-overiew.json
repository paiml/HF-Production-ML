{"text":" Whisper.apr is a good example of how to take a model, convert it to a smaller format, and then run it in a web assembly based ecosystem, but also allow yourself to use a command line tool. This dual purpose type of large language model conversion is really the future of using models that are stored on places like hugging face. If we take a look at the audio pipeline, a few things out. First up here, the audio is coming in from the microphone, in the case of the Web Assembly browser. You then resample it, convert it to mail, spectrogram, and then at that point you have the ability to put it into the model. In this case, we have 30 second chunks max and then voice activation detection as well. And you also have the ability to translate to other languages. In terms of the transformer architecture, classic encoder decoder transformer. In the case of the encoder, two convolutional layers are the feature extraction. And then they go to self-attention layers depending on the model size. And then finally they finish with the feed forward network. And if you look at the cross-attention, this is going to connect the encoder to the decoder. And the case of the decoder, you have 51,000 token of a capillary can also do cross-attention for the encoder outputs. And then the key value cache allows for auto- regressive generation. So the idea here is that once you set up this pipeline, you have the ability to wire it into a web-based browser. And in the case of web assembly, because it isn't running any JavaScript, it's high quality, your rust code, you're going to get both the quality and you're also going to get the performance can run these things without a GPU as well. In terms of the model variations here, the original whisper had a tiny which is 20 megabytes after the quantization and it can be three times faster than real time. The base is 37 megabytes. The small is 100 or so megabytes and then the medium is about 400 and you start to get much slower as you get into the bigger models. prato optimal when you look at the correct model to choose based on the size, especially for web assembly because loading a very large model doesn't make sense. If you load a smaller model, you get good enough performance. And this is something that you can experiment with in the repository for whisper.apr and play around with it yourself with different models. In terms of the web assembly architecture, it's a test first architecture and it's built purely in rust there's only a shim in JavaScript you get extreme level of tracing and quality and also you have the ability to run things in the background as web workers because other things happen just beyond the model. For example, you need to capture the audio, you need to display the audio, you need to have feedback loops that show the users button pressing looking at web assembly, it's beyond just a single threaded application. It has to be done in a multi-threaded and coherent way so that the user is able to do this. And then in terms of real-time streaming, as well, you can have the output go through and peer on the browser. And then in terms of the model format, this model format is what powers this web assembly ecosystem. And this tiny size can load in milliseconds as well and another thing you can do with this model format as allow a user potentially to upload and download any model they want to the web assembly application because it's running off of line. Finally, on the back end you have a command layout tool that can batch convert and be four files or wave files and you can actually customize that yourself. So once you start to treat model part of a traditional software engineering ecosystem and they become demystified. It really opens up the power of MLOPS.","segments":[]}